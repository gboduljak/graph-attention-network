{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrEINMv8xrrb",
        "outputId": "73c8dfc5-2585-4900-ac25-e6c68abcbf6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.0+cu116\n"
          ]
        }
      ],
      "source": [
        "# Check PyTorch version installed on this system\n",
        "!python -c \"import torch; print(torch.__version__)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AUKBJ8Z0neS",
        "outputId": "23c1bd5b-bb09-491e-f425-1f4e9b8767f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Dec 15 05:23:43 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    40W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uWUAAH_XxxWC",
        "outputId": "1db0fd26-9e88-46d3-c67e-ab3726f6cfa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: TORCH=1.13.0+cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (9.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.4 MB 4.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.0+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.15%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.15+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[K     |████████████████████████████████| 564 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 59.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.9.24)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=3c93a82151eb6bda24185e2bb5475fb6a7390e08eb58a97b3b13a43a526527eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/a3/20/198928106d3169865ae73afcbd3d3d1796cf6b429b55c65378\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: psutil, torch-geometric\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed psutil-5.9.4 torch-geometric-2.2.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[K     |████████████████████████████████| 512 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (2.8.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "# Download the required modules\n",
        "\"\"\"\n",
        "Assign to TORCH with what you get from the cell above, E.g., export TORCH=1.13.0+cu116\n",
        "\"\"\"\n",
        "%env TORCH=1.13.0+cu116\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-geometric\n",
        "!pip install torchmetrics\n",
        "!pip install matplotlib\n",
        "!pip install networkx\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaHOK91EyGuR",
        "outputId": "e1714903-bc45-4766-9ffd-2d9c7cce6fe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: github_repository=grl\n"
          ]
        }
      ],
      "source": [
        "github_username=\"\"\n",
        "github_repository=\"grl\"\n",
        "github_token = \"\"\n",
        "\n",
        "%env github_repository={github_repository}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWUxyUz_x8et",
        "outputId": "43dff435-fa1d-4c95-9074-1bc03fa3c61e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'grl'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 60 (delta 5), reused 15 (delta 2), pack-reused 39\u001b[K\n",
            "Unpacking objects: 100% (60/60), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://{github_token}@github.com/{github_username}/{github_repository}.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtuxeTnU17rM",
        "outputId": "13eab79a-bf60-4ea6-b468-5653372cb516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/grl\n"
          ]
        }
      ],
      "source": [
        "%cd $github_repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6SbBZVV0Ek6",
        "outputId": "434a16b1-594d-4dc9-8ce2-ea8539bf44a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f73d93e27b0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohY0SVKP0Fb5",
        "outputId": "31d6b310-fdd2-4ecf-e7b6-af200385f3d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://data.dgl.ai/dataset/ppi.zip\n",
            "Extracting ./ppi.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import PPI\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.transforms import AddSelfLoops\n",
        "import dataset\n",
        "\n",
        "train_dataset = PPI(root='', split='train', transform=AddSelfLoops())\n",
        "val_dataset = PPI(root='', split='val', transform=AddSelfLoops())\n",
        "test_dataset = PPI(root='', split='test', transform=AddSelfLoops())\n",
        "\n",
        "dataset.num_features = 50\n",
        "dataset.num_labels = 121\n",
        "dataset.train_loader = DataLoader(train_dataset, batch_size=2)\n",
        "dataset.val_loader = DataLoader(val_dataset, batch_size=2)\n",
        "dataset.test_loader = DataLoader(test_dataset, batch_size=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IXxawUNr0Hnp"
      },
      "outputs": [],
      "source": [
        "from evaluation import evaluate\n",
        "from training_loop import train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXAdnAV20MvV",
        "outputId": "d49e3048-d6e2-42b7-e634-d28fc23caac0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(0.6931, device='cuda:0'), tensor(0.3787, device='cuda:0'))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from models import GCNPPI\n",
        "model = GCNPPI(dataset.num_features, dataset.num_labels)\n",
        "evaluate(model, dataset.test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OAupMVsO0Oup"
      },
      "outputs": [],
      "source": [
        "ppi_train_params = {\n",
        "  \"lr\": 5e-3,\n",
        "  \"weight_decay\": 0,\n",
        "  \"epochs\": 400,\n",
        "  \"patience\": 100,\n",
        "  \"model_name\": model.model_name\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FG6MKVHQ0RC8"
      },
      "outputs": [],
      "source": [
        "def run_experiment(iters=10):\n",
        "  losses = []\n",
        "  scores = []\n",
        "  for iter in range(iters):\n",
        "    best_model, _, _, _, _, _ = train(model, ppi_train_params, verbose=False)\n",
        "    loss, score = evaluate(best_model, dataset.test_loader)\n",
        "    losses.append(loss)\n",
        "    scores.append(score)\n",
        "  losses = torch.tensor(losses)\n",
        "  scores = torch.tensor(scores)\n",
        "  return (torch.std_mean(losses), torch.std_mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEReyXD4i3bh",
        "outputId": "73674829-e040-46ed-90ec-569e4a931724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (encoder): Sequential(\n",
            "    (0): GCNConv(50, 1024)\n",
            "    (1): GCNConv(1024, 1024)\n",
            "  )\n",
            "  (classifier): GCNConv(1024, 121)\n",
            ")\n",
            "training...\n",
            "early stopping...\n",
            "best model performance @ epoch 00017: \n",
            "\tval_loss: 0.6156 | val_micro_f1: 0.4983\n",
            "\ttest_loss: 0.6044 | test_micro_f1: 0.5069\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (encoder): Sequential(\n",
            "    (0): GCNConv(50, 1024)\n",
            "    (1): GCNConv(1024, 1024)\n",
            "  )\n",
            "  (classifier): GCNConv(1024, 121)\n",
            ")\n",
            "training...\n",
            "early stopping...\n",
            "best model performance @ epoch 00008: \n",
            "\tval_loss: 0.6165 | val_micro_f1: 0.4972\n",
            "\ttest_loss: 0.6055 | test_micro_f1: 0.5064\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (encoder): Sequential(\n",
            "    (0): GCNConv(50, 1024)\n",
            "    (1): GCNConv(1024, 1024)\n",
            "  )\n",
            "  (classifier): GCNConv(1024, 121)\n",
            ")\n",
            "training...\n",
            "early stopping...\n",
            "best model performance @ epoch 00006: \n",
            "\tval_loss: 0.6177 | val_micro_f1: 0.4968\n",
            "\ttest_loss: 0.6066 | test_micro_f1: 0.5061\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (encoder): Sequential(\n",
            "    (0): GCNConv(50, 1024)\n",
            "    (1): GCNConv(1024, 1024)\n",
            "  )\n",
            "  (classifier): GCNConv(1024, 121)\n",
            ")\n",
            "training...\n",
            "early stopping...\n",
            "best model performance @ epoch 00009: \n",
            "\tval_loss: 0.6163 | val_micro_f1: 0.4998\n",
            "\ttest_loss: 0.6051 | test_micro_f1: 0.5092\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (encoder): Sequential(\n",
            "    (0): GCNConv(50, 1024)\n",
            "    (1): GCNConv(1024, 1024)\n",
            "  )\n",
            "  (classifier): GCNConv(1024, 121)\n",
            ")\n",
            "training...\n",
            "early stopping...\n",
            "best model performance @ epoch 00017: \n",
            "\tval_loss: 0.6154 | val_micro_f1: 0.4975\n",
            "\ttest_loss: 0.6040 | test_micro_f1: 0.5062\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (encoder): Sequential(\n",
            "    (0): GCNConv(50, 1024)\n",
            "    (1): GCNConv(1024, 1024)\n",
            "  )\n",
            "  (classifier): GCNConv(1024, 121)\n",
            ")\n",
            "training...\n",
            "early stopping...\n",
            "best model performance @ epoch 00009: \n",
            "\tval_loss: 0.6166 | val_micro_f1: 0.4989\n",
            "\ttest_loss: 0.6051 | test_micro_f1: 0.5079\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (encoder): Sequential(\n",
            "    (0): GCNConv(50, 1024)\n",
            "    (1): GCNConv(1024, 1024)\n",
            "  )\n",
            "  (classifier): GCNConv(1024, 121)\n",
            ")\n",
            "training...\n",
            "early stopping...\n",
            "best model performance @ epoch 00008: \n",
            "\tval_loss: 0.6166 | val_micro_f1: 0.4963\n",
            "\ttest_loss: 0.6051 | test_micro_f1: 0.5051\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (encoder): Sequential(\n",
            "    (0): GCNConv(50, 1024)\n",
            "    (1): GCNConv(1024, 1024)\n",
            "  )\n",
            "  (classifier): GCNConv(1024, 121)\n",
            ")\n",
            "training...\n",
            "early stopping...\n",
            "best model performance @ epoch 00008: \n",
            "\tval_loss: 0.6161 | val_micro_f1: 0.4965\n",
            "\ttest_loss: 0.6054 | test_micro_f1: 0.5057\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (encoder): Sequential(\n",
            "    (0): GCNConv(50, 1024)\n",
            "    (1): GCNConv(1024, 1024)\n",
            "  )\n",
            "  (classifier): GCNConv(1024, 121)\n",
            ")\n",
            "training...\n",
            "early stopping...\n",
            "best model performance @ epoch 00009: \n",
            "\tval_loss: 0.6165 | val_micro_f1: 0.4988\n",
            "\ttest_loss: 0.6052 | test_micro_f1: 0.5070\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (encoder): Sequential(\n",
            "    (0): GCNConv(50, 1024)\n",
            "    (1): GCNConv(1024, 1024)\n",
            "  )\n",
            "  (classifier): GCNConv(1024, 121)\n",
            ")\n",
            "training...\n",
            "early stopping...\n",
            "best model performance @ epoch 00008: \n",
            "\tval_loss: 0.6162 | val_micro_f1: 0.4988\n",
            "\ttest_loss: 0.6053 | test_micro_f1: 0.5081\n"
          ]
        }
      ],
      "source": [
        "loss_ci, score_ci = run_experiment(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCJrhqv7jqUS",
        "outputId": "3639bf48-5ddc-48b9-e851-f1b2bc315b86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss:\t\t0.6052 +/- 0.0007\n",
            "micro F1 score: 0.5069 +/- 0.0012\n"
          ]
        }
      ],
      "source": [
        "loss_std, loss_mean = loss_ci\n",
        "score_std, score_mean = score_ci\n",
        "\n",
        "print(f'loss:\\t\\t{loss_mean:.4f} +/- {loss_std:.4f}')\n",
        "print(f'micro F1 score: {score_mean:.4f} +/- {score_std:.4f}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.8.0 ('grl-env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "4737062b79cbd82e7f605897a0c10fa5613d72f803a33da3548714c1d9e40d67"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
