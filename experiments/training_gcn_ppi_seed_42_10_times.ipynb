{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrEINMv8xrrb",
        "outputId": "85bfcd41-b6a9-4917-96ea-fa5982d6622f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.0+cu116\n"
          ]
        }
      ],
      "source": [
        "# Check PyTorch version installed on this system\n",
        "!python -c \"import torch; print(torch.__version__)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AUKBJ8Z0neS",
        "outputId": "9246b980-0008-440d-da2d-de9697f0140f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Dec 26 02:31:00 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P0    28W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uWUAAH_XxxWC",
        "outputId": "a466283a-ec6c-4871-bfc2-c26c841309d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: TORCH=1.13.0+cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (9.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.4 MB 14.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.0+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.16%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 15.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.16+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[K     |████████████████████████████████| 564 kB 13.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 78.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=7f1172e59e0996c6e73cb9c44ad31fe8d7ab0563a1815bbec4465c008b1edca4\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/a3/20/198928106d3169865ae73afcbd3d3d1796cf6b429b55c65378\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: psutil, torch-geometric\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed psutil-5.9.4 torch-geometric-2.2.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[K     |████████████████████████████████| 512 kB 14.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0+cu116)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (2.8.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "# Download the required modules\n",
        "\"\"\"\n",
        "Assign to TORCH with what you get from the cell above, E.g., export TORCH=1.13.0+cu116\n",
        "\"\"\"\n",
        "%env TORCH=1.13.0+cu116\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-geometric\n",
        "!pip install torchmetrics\n",
        "!pip install matplotlib\n",
        "!pip install networkx\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaHOK91EyGuR",
        "outputId": "01c2ab7a-c0e2-44f2-acdd-fa04652c04a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: github_repository=grl\n"
          ]
        }
      ],
      "source": [
        "github_username=\"deeplearningtester\"\n",
        "github_repository=\"\"\n",
        "github_token = \"\"\n",
        "\n",
        "%env github_repository={github_repository}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWUxyUz_x8et",
        "outputId": "0b660a13-0b4c-46ad-8522-89aa08c4f718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'grl'...\n",
            "remote: Enumerating objects: 97, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 97 (delta 7), reused 20 (delta 4), pack-reused 70\u001b[K\n",
            "Unpacking objects: 100% (97/97), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://{github_token}@github.com/{github_username}/{github_repository}.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtuxeTnU17rM",
        "outputId": "07e61a12-8b47-4178-b7dd-a7a0a016d73b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/grl\n"
          ]
        }
      ],
      "source": [
        "%cd $github_repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6SbBZVV0Ek6",
        "outputId": "6aeedc52-f9f3-4700-dd6b-f33cb0551ac3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9f6950f4b0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohY0SVKP0Fb5",
        "outputId": "40e6be3f-0b19-419a-edf1-dc95999e651c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://data.dgl.ai/dataset/ppi.zip\n",
            "Extracting ./ppi.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import PPI\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.transforms import AddSelfLoops\n",
        "import dataset\n",
        "\n",
        "train_dataset = PPI(root='', split='train', transform=AddSelfLoops())\n",
        "val_dataset = PPI(root='', split='val', transform=AddSelfLoops())\n",
        "test_dataset = PPI(root='', split='test', transform=AddSelfLoops())\n",
        "\n",
        "dataset.num_features = 50\n",
        "dataset.num_labels = 121\n",
        "dataset.train_loader = DataLoader(train_dataset, batch_size=2)\n",
        "dataset.val_loader = DataLoader(val_dataset, batch_size=2)\n",
        "dataset.test_loader = DataLoader(test_dataset, batch_size=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IXxawUNr0Hnp"
      },
      "outputs": [],
      "source": [
        "from evaluation import evaluate\n",
        "from training_loop import train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXAdnAV20MvV",
        "outputId": "3685e58c-872a-46f7-b713-85eb1a8e2cf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(0.6935, device='cuda:0'), tensor(0.3772, device='cuda:0'))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from models import GCNPPI\n",
        "model = GCNPPI(dataset.num_features, dataset.num_labels)\n",
        "evaluate(model, dataset.test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OAupMVsO0Oup"
      },
      "outputs": [],
      "source": [
        "ppi_train_params = {\n",
        "  \"lr\": 5e-3,\n",
        "  \"weight_decay\": 0,\n",
        "  \"epochs\": 400,\n",
        "  \"patience\": 100,\n",
        "  \"model_name\": model.model_name\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FG6MKVHQ0RC8"
      },
      "outputs": [],
      "source": [
        "def run_experiment(iters=10):\n",
        "  losses = []\n",
        "  scores = []\n",
        "  for iter in range(iters):\n",
        "    best_model, _, _, _, _, _ = train(model, ppi_train_params, verbose=False)\n",
        "    loss, score = evaluate(best_model, dataset.test_loader)\n",
        "    losses.append(loss)\n",
        "    scores.append(score)\n",
        "  losses = torch.tensor(losses)\n",
        "  scores = torch.tensor(scores)\n",
        "  return (torch.std_mean(losses), torch.std_mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEReyXD4i3bh",
        "outputId": "563a2824-6493-44bb-bd84-d739454017bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (fst_layer): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "  )\n",
            "  (snd_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 256)\n",
            "    (1): GCNConv(1024, 256)\n",
            "    (2): GCNConv(1024, 256)\n",
            "    (3): GCNConv(1024, 256)\n",
            "  )\n",
            "  (last_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 121)\n",
            "    (1): GCNConv(1024, 121)\n",
            "    (2): GCNConv(1024, 121)\n",
            "    (3): GCNConv(1024, 121)\n",
            "    (4): GCNConv(1024, 121)\n",
            "    (5): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skip_to_snd): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "  )\n",
            "  (skip_to_last): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "    (4): GCNConv(1024, 256)\n",
            "    (5): GCNConv(1024, 256)\n",
            "    (6): GCNConv(1024, 256)\n",
            "    (7): GCNConv(1024, 256)\n",
            "    (8): GCNConv(1024, 121)\n",
            "    (9): GCNConv(1024, 121)\n",
            "    (10): GCNConv(1024, 121)\n",
            "    (11): GCNConv(1024, 121)\n",
            "    (12): GCNConv(1024, 121)\n",
            "    (13): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skips): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (6): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (7): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (8): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (9): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            ")\n",
            "training...\n",
            "best model performance @ epoch 00177: \n",
            "\tval_loss: 0.1416 | val_micro_f1: 0.9391\n",
            "\ttest_loss: 0.0896 | test_micro_f1: 0.9577\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (fst_layer): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "  )\n",
            "  (snd_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 256)\n",
            "    (1): GCNConv(1024, 256)\n",
            "    (2): GCNConv(1024, 256)\n",
            "    (3): GCNConv(1024, 256)\n",
            "  )\n",
            "  (last_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 121)\n",
            "    (1): GCNConv(1024, 121)\n",
            "    (2): GCNConv(1024, 121)\n",
            "    (3): GCNConv(1024, 121)\n",
            "    (4): GCNConv(1024, 121)\n",
            "    (5): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skip_to_snd): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "  )\n",
            "  (skip_to_last): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "    (4): GCNConv(1024, 256)\n",
            "    (5): GCNConv(1024, 256)\n",
            "    (6): GCNConv(1024, 256)\n",
            "    (7): GCNConv(1024, 256)\n",
            "    (8): GCNConv(1024, 121)\n",
            "    (9): GCNConv(1024, 121)\n",
            "    (10): GCNConv(1024, 121)\n",
            "    (11): GCNConv(1024, 121)\n",
            "    (12): GCNConv(1024, 121)\n",
            "    (13): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skips): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (6): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (7): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (8): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (9): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            ")\n",
            "training...\n",
            "best model performance @ epoch 00208: \n",
            "\tval_loss: 0.1396 | val_micro_f1: 0.9434\n",
            "\ttest_loss: 0.0913 | test_micro_f1: 0.9593\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (fst_layer): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "  )\n",
            "  (snd_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 256)\n",
            "    (1): GCNConv(1024, 256)\n",
            "    (2): GCNConv(1024, 256)\n",
            "    (3): GCNConv(1024, 256)\n",
            "  )\n",
            "  (last_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 121)\n",
            "    (1): GCNConv(1024, 121)\n",
            "    (2): GCNConv(1024, 121)\n",
            "    (3): GCNConv(1024, 121)\n",
            "    (4): GCNConv(1024, 121)\n",
            "    (5): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skip_to_snd): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "  )\n",
            "  (skip_to_last): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "    (4): GCNConv(1024, 256)\n",
            "    (5): GCNConv(1024, 256)\n",
            "    (6): GCNConv(1024, 256)\n",
            "    (7): GCNConv(1024, 256)\n",
            "    (8): GCNConv(1024, 121)\n",
            "    (9): GCNConv(1024, 121)\n",
            "    (10): GCNConv(1024, 121)\n",
            "    (11): GCNConv(1024, 121)\n",
            "    (12): GCNConv(1024, 121)\n",
            "    (13): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skips): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (6): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (7): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (8): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (9): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            ")\n",
            "training...\n",
            "best model performance @ epoch 00219: \n",
            "\tval_loss: 0.1455 | val_micro_f1: 0.9433\n",
            "\ttest_loss: 0.0927 | test_micro_f1: 0.9596\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (fst_layer): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "  )\n",
            "  (snd_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 256)\n",
            "    (1): GCNConv(1024, 256)\n",
            "    (2): GCNConv(1024, 256)\n",
            "    (3): GCNConv(1024, 256)\n",
            "  )\n",
            "  (last_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 121)\n",
            "    (1): GCNConv(1024, 121)\n",
            "    (2): GCNConv(1024, 121)\n",
            "    (3): GCNConv(1024, 121)\n",
            "    (4): GCNConv(1024, 121)\n",
            "    (5): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skip_to_snd): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "  )\n",
            "  (skip_to_last): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "    (4): GCNConv(1024, 256)\n",
            "    (5): GCNConv(1024, 256)\n",
            "    (6): GCNConv(1024, 256)\n",
            "    (7): GCNConv(1024, 256)\n",
            "    (8): GCNConv(1024, 121)\n",
            "    (9): GCNConv(1024, 121)\n",
            "    (10): GCNConv(1024, 121)\n",
            "    (11): GCNConv(1024, 121)\n",
            "    (12): GCNConv(1024, 121)\n",
            "    (13): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skips): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (6): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (7): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (8): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (9): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            ")\n",
            "training...\n",
            "best model performance @ epoch 00281: \n",
            "\tval_loss: 0.1391 | val_micro_f1: 0.9519\n",
            "\ttest_loss: 0.0851 | test_micro_f1: 0.9676\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (fst_layer): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "  )\n",
            "  (snd_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 256)\n",
            "    (1): GCNConv(1024, 256)\n",
            "    (2): GCNConv(1024, 256)\n",
            "    (3): GCNConv(1024, 256)\n",
            "  )\n",
            "  (last_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 121)\n",
            "    (1): GCNConv(1024, 121)\n",
            "    (2): GCNConv(1024, 121)\n",
            "    (3): GCNConv(1024, 121)\n",
            "    (4): GCNConv(1024, 121)\n",
            "    (5): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skip_to_snd): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "  )\n",
            "  (skip_to_last): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "    (4): GCNConv(1024, 256)\n",
            "    (5): GCNConv(1024, 256)\n",
            "    (6): GCNConv(1024, 256)\n",
            "    (7): GCNConv(1024, 256)\n",
            "    (8): GCNConv(1024, 121)\n",
            "    (9): GCNConv(1024, 121)\n",
            "    (10): GCNConv(1024, 121)\n",
            "    (11): GCNConv(1024, 121)\n",
            "    (12): GCNConv(1024, 121)\n",
            "    (13): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skips): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (6): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (7): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (8): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (9): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            ")\n",
            "training...\n",
            "best model performance @ epoch 00157: \n",
            "\tval_loss: 0.1389 | val_micro_f1: 0.9376\n",
            "\ttest_loss: 0.0896 | test_micro_f1: 0.9561\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (fst_layer): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "  )\n",
            "  (snd_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 256)\n",
            "    (1): GCNConv(1024, 256)\n",
            "    (2): GCNConv(1024, 256)\n",
            "    (3): GCNConv(1024, 256)\n",
            "  )\n",
            "  (last_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 121)\n",
            "    (1): GCNConv(1024, 121)\n",
            "    (2): GCNConv(1024, 121)\n",
            "    (3): GCNConv(1024, 121)\n",
            "    (4): GCNConv(1024, 121)\n",
            "    (5): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skip_to_snd): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "  )\n",
            "  (skip_to_last): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "    (4): GCNConv(1024, 256)\n",
            "    (5): GCNConv(1024, 256)\n",
            "    (6): GCNConv(1024, 256)\n",
            "    (7): GCNConv(1024, 256)\n",
            "    (8): GCNConv(1024, 121)\n",
            "    (9): GCNConv(1024, 121)\n",
            "    (10): GCNConv(1024, 121)\n",
            "    (11): GCNConv(1024, 121)\n",
            "    (12): GCNConv(1024, 121)\n",
            "    (13): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skips): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (6): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (7): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (8): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (9): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            ")\n",
            "training...\n",
            "best model performance @ epoch 00193: \n",
            "\tval_loss: 0.1416 | val_micro_f1: 0.9407\n",
            "\ttest_loss: 0.0901 | test_micro_f1: 0.9586\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (fst_layer): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "  )\n",
            "  (snd_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 256)\n",
            "    (1): GCNConv(1024, 256)\n",
            "    (2): GCNConv(1024, 256)\n",
            "    (3): GCNConv(1024, 256)\n",
            "  )\n",
            "  (last_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 121)\n",
            "    (1): GCNConv(1024, 121)\n",
            "    (2): GCNConv(1024, 121)\n",
            "    (3): GCNConv(1024, 121)\n",
            "    (4): GCNConv(1024, 121)\n",
            "    (5): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skip_to_snd): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "  )\n",
            "  (skip_to_last): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "    (4): GCNConv(1024, 256)\n",
            "    (5): GCNConv(1024, 256)\n",
            "    (6): GCNConv(1024, 256)\n",
            "    (7): GCNConv(1024, 256)\n",
            "    (8): GCNConv(1024, 121)\n",
            "    (9): GCNConv(1024, 121)\n",
            "    (10): GCNConv(1024, 121)\n",
            "    (11): GCNConv(1024, 121)\n",
            "    (12): GCNConv(1024, 121)\n",
            "    (13): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skips): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (6): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (7): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (8): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (9): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            ")\n",
            "training...\n",
            "best model performance @ epoch 00192: \n",
            "\tval_loss: 0.1399 | val_micro_f1: 0.9409\n",
            "\ttest_loss: 0.0893 | test_micro_f1: 0.9593\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (fst_layer): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "  )\n",
            "  (snd_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 256)\n",
            "    (1): GCNConv(1024, 256)\n",
            "    (2): GCNConv(1024, 256)\n",
            "    (3): GCNConv(1024, 256)\n",
            "  )\n",
            "  (last_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 121)\n",
            "    (1): GCNConv(1024, 121)\n",
            "    (2): GCNConv(1024, 121)\n",
            "    (3): GCNConv(1024, 121)\n",
            "    (4): GCNConv(1024, 121)\n",
            "    (5): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skip_to_snd): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "  )\n",
            "  (skip_to_last): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "    (4): GCNConv(1024, 256)\n",
            "    (5): GCNConv(1024, 256)\n",
            "    (6): GCNConv(1024, 256)\n",
            "    (7): GCNConv(1024, 256)\n",
            "    (8): GCNConv(1024, 121)\n",
            "    (9): GCNConv(1024, 121)\n",
            "    (10): GCNConv(1024, 121)\n",
            "    (11): GCNConv(1024, 121)\n",
            "    (12): GCNConv(1024, 121)\n",
            "    (13): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skips): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (6): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (7): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (8): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (9): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            ")\n",
            "training...\n",
            "best model performance @ epoch 00293: \n",
            "\tval_loss: 0.1363 | val_micro_f1: 0.9536\n",
            "\ttest_loss: 0.0815 | test_micro_f1: 0.9686\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (fst_layer): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "  )\n",
            "  (snd_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 256)\n",
            "    (1): GCNConv(1024, 256)\n",
            "    (2): GCNConv(1024, 256)\n",
            "    (3): GCNConv(1024, 256)\n",
            "  )\n",
            "  (last_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 121)\n",
            "    (1): GCNConv(1024, 121)\n",
            "    (2): GCNConv(1024, 121)\n",
            "    (3): GCNConv(1024, 121)\n",
            "    (4): GCNConv(1024, 121)\n",
            "    (5): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skip_to_snd): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "  )\n",
            "  (skip_to_last): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "    (4): GCNConv(1024, 256)\n",
            "    (5): GCNConv(1024, 256)\n",
            "    (6): GCNConv(1024, 256)\n",
            "    (7): GCNConv(1024, 256)\n",
            "    (8): GCNConv(1024, 121)\n",
            "    (9): GCNConv(1024, 121)\n",
            "    (10): GCNConv(1024, 121)\n",
            "    (11): GCNConv(1024, 121)\n",
            "    (12): GCNConv(1024, 121)\n",
            "    (13): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skips): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (6): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (7): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (8): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (9): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            ")\n",
            "training...\n",
            "best model performance @ epoch 00190: \n",
            "\tval_loss: 0.1435 | val_micro_f1: 0.9400\n",
            "\ttest_loss: 0.0905 | test_micro_f1: 0.9575\n",
            "training model GCNPPI\n",
            "GCNPPI(\n",
            "  (fst_layer): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "  )\n",
            "  (snd_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 256)\n",
            "    (1): GCNConv(1024, 256)\n",
            "    (2): GCNConv(1024, 256)\n",
            "    (3): GCNConv(1024, 256)\n",
            "  )\n",
            "  (last_layer): ModuleList(\n",
            "    (0): GCNConv(1024, 121)\n",
            "    (1): GCNConv(1024, 121)\n",
            "    (2): GCNConv(1024, 121)\n",
            "    (3): GCNConv(1024, 121)\n",
            "    (4): GCNConv(1024, 121)\n",
            "    (5): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skip_to_snd): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "  )\n",
            "  (skip_to_last): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0): GCNConv(50, 256)\n",
            "    (1): GCNConv(50, 256)\n",
            "    (2): GCNConv(50, 256)\n",
            "    (3): GCNConv(50, 256)\n",
            "    (4): GCNConv(1024, 256)\n",
            "    (5): GCNConv(1024, 256)\n",
            "    (6): GCNConv(1024, 256)\n",
            "    (7): GCNConv(1024, 256)\n",
            "    (8): GCNConv(1024, 121)\n",
            "    (9): GCNConv(1024, 121)\n",
            "    (10): GCNConv(1024, 121)\n",
            "    (11): GCNConv(1024, 121)\n",
            "    (12): GCNConv(1024, 121)\n",
            "    (13): GCNConv(1024, 121)\n",
            "  )\n",
            "  (skips): ModuleList(\n",
            "    (0): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (1): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (3): Linear(in_features=1024, out_features=256, bias=False)\n",
            "    (4): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (5): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (6): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (7): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (8): Linear(in_features=1024, out_features=121, bias=False)\n",
            "    (9): Linear(in_features=1024, out_features=121, bias=False)\n",
            "  )\n",
            ")\n",
            "training...\n",
            "best model performance @ epoch 00227: \n",
            "\tval_loss: 0.1414 | val_micro_f1: 0.9449\n",
            "\ttest_loss: 0.0890 | test_micro_f1: 0.9612\n"
          ]
        }
      ],
      "source": [
        "loss_ci, score_ci = run_experiment(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCJrhqv7jqUS",
        "outputId": "e53694bd-0609-46e9-9e98-917144ab0ee6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss:\t\t0.0889 +/- 0.0032\n",
            "micro F1 score: 0.9606 +/- 0.0042\n"
          ]
        }
      ],
      "source": [
        "loss_std, loss_mean = loss_ci\n",
        "score_std, score_mean = score_ci\n",
        "\n",
        "print(f'loss:\\t\\t{loss_mean:.4f} +/- {loss_std:.4f}')\n",
        "print(f'micro F1 score: {score_mean:.4f} +/- {score_std:.4f}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.0 ('grl-env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "4737062b79cbd82e7f605897a0c10fa5613d72f803a33da3548714c1d9e40d67"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
